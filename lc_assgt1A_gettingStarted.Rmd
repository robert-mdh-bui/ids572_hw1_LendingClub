---
title: "R Notebook - Getting started with Assignment 1A on the Lending Club case"
author: "sid b"
date: "Sept 12, 2021"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 


```{r}
library(tidyverse)
library(lubridate)
```


The lcData100K.csv file contains a sample of data on 3-year loans  which we will use for this analyses
```{r}

lcdf <- read_csv('lcData100K/lcData100K.csv')
```



#Explore the data
```{r}

#How does loan status vary by loan grade
lcdf %>% group_by(loan_status, grade) %>% tally()
#or, using table
table(lcdf$loan_status, lcdf$grade)
#   Do you have loans with status other than "Fully Paid" or "Charged Off"?  
#    If so, you should filter these out. For example, if there are some loans with status of "current", 
#       you can filter these out by lcdf <- lcdf %>%  filter(loan_status !="Current")


#How does number of loans, loan amount, interest rate vary by grade
lcdf %>% group_by(grade) %>% tally()
lcdf %>% group_by(grade) %>% summarise(sum(loan_amnt))   #and/or what is the mean loan_amnt by grade?
lcdf %>% group_by(grade) %>% summarise(mean(int_rate))

#Or plot these..
ggplot(lcdf, aes( x = int_rate)) + geom_histogram()
ggplot(lcdf, aes( x = loan_amnt)) + geom_histogram(aes(fill=grade))
ggplot(lcdf, aes( x = loan_amnt)) + geom_histogram() + facet_wrap(~loan_status)

#.....

#As discussed in the case, LendingClub assigns a grade to each loan, from A through G. How many loans are in each grade? What is the default rate in each grade? 
#What is the average interest rate in each grade? What about the average percentage (annual) return? Do these numbers surprise you? If you had to invest in one grade only, which loans would you #invest in?"
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt))

```


Examine actual returns from a loan, and relation with int_rate
(for example, can one expect a 5%/year return from a loan with 5% int_rate?)
```{r}

#do loans return an amount as may be expected from the int_rate ? 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt) %>% head()


#calculate the annualized percentage return
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#summarize by grade
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#Where do the negative numbers for minRet come from?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% head()

#are these all from 'Charged Off' loans?
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet) %>% filter(annRet < 0) %>% count(loan_status)

```



Are some loans paid back early, what proportion ?  
  - calculate the actual loan term, i.e. the time by which a loan is fully paid back
What is the actual return from inventment in a loan?
```{r}
#Term of the loan is the duration between the last-payment-date and the loan issue-date
#   First check the format of these two columns with date values
head(lcdf[, c("last_pymnt_d", "issue_d")])

 #Notice that issue_d is a date variable (of type date), while last_pymnt_d is of type character (like "Dec-2018", having month-year but no date). 
#So we need to first change the character type to date:
#     First step is to past "01-" to the character string, to get something like "01-Dec-2018", i.e. first of each month 
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
#     Then convert this character to a date type variable
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")

#Check their format now
head(lcdf[, c("last_pymnt_d", "issue_d")])


#Now we can compute the duration between two dates using 
#      as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d))
#   This will return the duration in seconds -- try  
#          x<- as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)
#          head(x)
#     To convert it to duration in weeks, we can use 
#          x<- as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dweeks(1)
#      Or to get the duration in years
#          x<- as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1)
#
#Another issue to consider: what about those loans which are charged-off? These are not paid back fully by the end of the 3-year term, so the duration as calculated above will not give the accurate value for the actual-term. For these loans, we can set the actual-term at 3.

lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)

#Then, considering this actual term, the actual annual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#take a look these variables for the first few rows of data 
lcdf %>% select(loan_status, int_rate, funded_amnt, total_pymnt, annRet, actualTerm, actualReturn) %>%  head()
   # CHECK that this is accurate and does what you are looking for

```


Some further analyses
```{r}

#For cost-based performance, we may want to see the average interest rate, and the average of proportion of loan amount paid back, grouped by loan_status
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt)  )
# Notice that the totRet on Charged Off loans as negative, so, for every dollar invested, there is a loss (how much?).

#does this vary by loan_type?  Here, we are expressing totRet as a % value
lcdf%>% group_by(loan_status, grade) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt)*100 )
     #Is this in line with what you'd expect (from loan grade info)?



# For Fully Paid loans, is the average value of totRet what you'd expect, considering the average value for intRate?
# Consider - if a loan were to be paid back over the full 3-year period, what would you expect for average expected total-return? And how does this compare with average of the actual totRet?
#(the totRet seems less than what may be  expected from intRate -- is this because many loans are paid back earlier).

#This summary can also help understand:
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt), avgActRet=mean(actualReturn)  )


#you may like to look at some of these variables
lcdf %>% select(loan_status, loan_amnt, funded_amnt, total_pymnt, int_rate, actualTerm, actualReturn ) %>% view()

#some more summaries
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)

lcdf %>% group_by(loan_status) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)


```




Further data exploration -- look into emp_length
```{r}
#what are the different values, and how many examples are there for each value
lcdf %>% group_by(emp_length) %>% tally()

#convert emp_length to factor -- with factor levels ordered in a meaningful way
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))
# Note: we could have converted to factor by simply using 
#    x<-as.factor(lcdf$emp_length), 
#   but here the factor levels would be randomly arranged


#Do defaults vary by emp_length?
table(lcdf$loan_status, lcdf$emp_length)
  #this shows nujmber of Charged Off and Full Paid loans for different emp_length
#Can we calculate the proportion of Ca=harged Off loans for weach level of emp_length?
cc=table(lcdf$loan_status, lcdf$emp_length)
cc[1,]/(cc[1,] + cc[2,])   #dividing each element of the first row in cc by the sum of first and second row elements.


#Does the loan-grade assigned by LC vary by emp_length?
table(lcdf$grade, lcdf$emp_length)


#some addl summary by emp_length
lcdf %>% group_by(emp_length) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

```


Further data exploration -- look into loan purpose
```{r}
# Does default rate, int-rate, etc vary by loan purpose
lcdf %>% group_by(purpose) %>% tally()
lcdf %>% group_by(purpose) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), defaultRate=defaults/nLoans, avgIntRate=mean(int_rate),  avgLoanAmt=mean(loan_amnt),  avgActRet = mean(actualReturn), avgActTerm=mean(actualTerm))

#Does loan-grade vary by purpose?
table(lcdf$purpose, lcdf$grade)


#some other detailed analyses
#Does loan purpose relate to emp_length?
table(lcdf$purpose, lcdf$emp_length)

#do those with home-improvement loans own or rent a home?
table(lcdf$home_ownership, lcdf$purpose)



lcdf %>% group_by(purpose) %>% tally()
#some of category levels have very few examples 
#    do you want to recode such categories with very few cases to "other"
lcdf$purpose <- fct_recode(lcdf$purpose, other="wedding", other="educational", other="renewable_energy")


#Plot of loan amount by purpose
boxplot(lcdf$loan_amnt ~ lcdf$purpose)

```




Some derived attributes
```{r}
#Derived attribute: proportion of satisfactory bankcard accounts 
lcdf$propSatisBankcardAccts <- ifelse(lcdf$num_bc_tl>0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)
 
#Another one - lets calculate the length of borrower's history with LC
#  i.e time between earliest_cr_line and issue_d
#  Look at these variables - you will notice that earliest_cr_line is read in as 'chr', we first convert it to date
#      and then subtract the two dates
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")

#lcdf$issue_d<-parse_date_time(lcdf$issue_d, "myd") <<---we should not do this, since issue_d is already a date type variable
 
# we can use the lubridate functions to precisely handle date-times durations
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)


#Another new attribute: ratio of openAccounts to totalAccounts
#lcdf$openAccRatio <- 



#does LC-assigned loan grade vary by borrHistory?
lcdf %>% group_by(grade) %>% summarise(avgBorrHist=mean(borrHistory))


#some additional analyses.......(your own)

```


Converting character variables
```{r}
#Take a look at the variables in the data-set -- are there any variable type changes you want to consider?
glimpse(lcdf)

#  notice that there are a few character type variables - grade, sub_grade, verification_status,....
#   We can  convert all of these to factor
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

```




Drop some variables for potential leakage, others
```{r}

#Drop some other columns which are not useful and those which will cause 'leakage'
lcdf <- lcdf %>% select(-c(funded_amnt_inv, term, emp_title, pymnt_plan, title, zip_code, addr_state, out_prncp, out_prncp_inv, total_pymnt_inv, total_rec_prncp, total_rec_int,total_rec_late_fee,recoveries, collection_recovery_fee, last_credit_pull_d, policy_code, disbursement_method, debt_settlement_flag, hardship_flag, hardship_dpd, settlement_term, application_type))


#Another way -- suppose you want to drop some other variables we will not use in following analyses
#varsToRemove <- c("last_pymnt_d", "last_pymnt_amnt","annRet")
#lcdf <- lcdf %>% select(-varsToRemove)
  

```




Missing values
Why are the values missing? Are some of the missing values actaally 'zeros' which are not recorded in the data?
Is missing-ness informative in some way?  Are there, for example,  more/less defaults for cases where values on the attribute are missing ?
```{r}

#Drop variables with all empty values
lcdf <- lcdf %>% select_if(function(x){!all(is.na(x))})
 # How many variables were dropped ?  You can check by dim(lcdf), before and after this command 


#Of the columns remaining, names of columns with missing values
names(lcdf)[colSums(is.na(lcdf))>0]

#missing value proportions in each column
colMeans(is.na(lcdf))
# or, get only those columns where there are missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]


#Are there same number of missing values in a set of attributes, and might there be a reason for this?
#How does this inform your handling of missing values?


#Consider open_acc_6m, which has 97% missing
summary(as.factor(lcdf$open_acc_6m))    # shows the counts by different values of the variable
table(lcdf$open_acc_6m)  #gives the same output  -- but it does not show the NAs
# We can replace missing values in a variable with
#      replace_na( variable, "value for missing")     
table( replace_na( lcdf$open_acc_6m, "missing") )   # shows the 'missing' values
table( lcdf$loan_status, replace_na( lcdf$open_acc_6m, "missing") ) # shows counts by loan_status at different values of the variable

#to get a bar-plot of these
cc<-table( lcdf$loan_status, replace_na( lcdf$open_acc_6m, "missing") )
barplot(cc, col=c("darkblue","red"),legend = rownames(cc))  # here, one bar dominates others
# For a better display, we can get proportion of ChargedOff as cc[1,]/(cc[2,]+cc[1,]).  Then to plot this..
barplot(cc[1,]/(cc[2,]+cc[1,]), legend = rownames(cc), ylab = "prop ChargedOff", main="Prop ChargedOff by open_acc_6m")




#Consider the "mths_since_" variables -- what do they represent (see data dictionary.
# Are the missing values here due to zeros; or due to no known values in the period considered (then the actual value would be larger than the max value)? Or are are they really unknown?

#  Variable mths_since_last_record has more than 80% values missing
cc<-table( lcdf$loan_status, replace_na( lcdf$mths_since_last_record, "missing") )
cc[1,]/(cc[2,]+cc[1,])
# Is the proportion of defaults for 'missing' similar to the large/small values of the variable?  If they do not relate well to larger values, than we should not assume that missings are for values higher than the max.
#If a very large proportion of values is really unknown, may be better to not include this variable in a model?



#For mths_since_last_delinq, which has around 50% values missing 
cc<-table( lcdf$loan_status, replace_na( lcdf$mths_since_last_delinq, "missing") )
cc[1,]/(cc[2,]+cc[1,])
   #Here, is there a pattern of higher defaults for examples which have more recent delinquencies?  If so, we should try to retain this variable, and find a way to reasonably handle the missing values.
  


#For mths_since_recent_inq, which has around 10% values missing
cc<-table( lcdf$loan_status, replace_na( lcdf$mths_since_recent_inq, "missing") )
cc[1,]/(cc[2,]+cc[1,])
    # Here,the proportion of defaults for missing values seem similar to the larger values of the variable -- so, may be replace the missings with a large value ?




#Suppose you decide to remove variables which have more than 60% missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-nm)




#Impute missing values for remaining variables which have missing values
# - first get the columns with missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]

#summary of data in these columns
nm<- names(lcdf)[colSums(is.na(lcdf))>0]
summary(lcdf[, nm])


#Question -- considering DT based models, can we retain variables which have some (not too many) missing values ?


#Suppose we want to replace the missing values for variables where there are a larger number of missings, and where this seems reasonable (what is your logic for this?)

#For bc_open_to_buy, suppose we want to replace the missing values by the median
#  -- we will try this out and put results in a temporary dataset lcx, with the attributes that have missing values
lcx<-lcdf[, c(nm)]
lcx<- lcx %>% replace_na(list(bc_open_to_buy=median(lcx$bc_open_to_buy, na.rm=TRUE)))


#Similarly for the other variables
#After trying this out on the temporary dataframe lcx, if we are sure this is what we want, we can now  replace the missing values on the lcdf dataset

lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=-500, bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))
  # Check that the replacement values for missings are reasonable - we should be able to explain why we are doing this.


#Have this addressed all missing values?
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
  # we did not replace missings for all attributes - will this be ok for DT based models which we will develop in the next phase?




```





Univariate analyses - which variables are individually predictive of the outcome ?
Considering a single variable model to predict loan_status, what is a measure of performance?  AUC? 
For a univariate model with a variable, say, x1, what should we consider as the model 'score' for predicting loan_status? 
Can we take the values of x1 as the score for a model y_hat=f(x1) ? 

Can then compute the AUC for each variable
```{r}

library(pROC) #this package has a function auc(..) which we can readily use

#We will use the function auc(response, prediction) which returns the AUC value for the specified predictor variable, and considering the response variable as the dependent. 
#   Make sure you understand how this works.

# For example:
auc(response=lcdf$loan_status, lcdf$loan_amnt)
 # returns the auc value for loan_amt as the single predictor

#In the auc(..) function, the predictor variable has to be numeric  - otherwise, how would it calculate the AUC (think about how auc is calculated). 
# For a factor variable, we can consider the factor levels as numbers:
auc(response=lcdf$loan_status, as.numeric(lcdf$emp_length))


# There may be a few date type variables in the data - we will ignore these here.  
# (Data variables can be handled by converting to days-since variables) 



#How would you calculate AUC this for all variables in the dataset?
# Rather than call the function individually for each variable, we can use the sapply(..) function.
#  - look up how the sapply function works.  Similar to the apply() function.


# For the numeric variables:
aucsNum<-sapply(lcdf %>% select_if(is.numeric), auc, response=lcdf$loan_status)
  #Please make sure we understand what is happening here.  How does sapply work?


#Or considering both numeric and factor variables:
aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdf$loan_status) 
#aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), pROC::auc, response=lcdf$loan_status)



#TO determine which variables have auc > 0.5
aucAll[aucAll>0.5]

#Or, we can use the tidy(..) function from the broom package - which converts the 'messy' output into a tidy form as a tibble
library(broom)

tidy(aucAll[aucAll > 0.5]) %>% view()

# or  in any range of values like, tidy(aucAll[aucAll >=0.5 & aucAll < 0.6])
# or in sorted order
tidy(aucAll) %>% arrange(desc(aucAll))


```




Next we will build some models


Split the data into trn, text subsets
```{r}
TRNPROP = 0.5  #proportion of examples in the training sample

nr<-nrow(lcdf)
trnIndex<- sample(1:nr, size = round(TRNPROP * nr), replace=FALSE)

lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```






DT models using rpart
```{r}

#Do you want to use all the variables in the dataset as predictors ?
#Take a look at teh data
glimpse(lcdf)

#Are are some variable you want to exclude  - due to leakage, or other reasons?
#  What about variables like actualTerm, actualReturn which you calculated?
#       These will be useful in performance assessment, but should not be used in building the model.
#Are there any data variables which you may not want to use in developing the model?


varsOmit <- c('actualTerm', 'actcualReturn', 'issue_d')  #are there others?


library(rpart)

#It can be useful to convert the target variable, loan_status to  a factor variable
lcdf$loan_status <- factor(lcdf$loan_status, levels=c("Fully Paid", "Charged Off"))


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-varsOmit), method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30))
printcp(lcDT1)  #reasonable ?

#variable importance
lcDT1$variable.importance
  # Does this look reasonable?  Any leakage causing variables can show up as highly important !


lcDT1 <- rpart(loan_status ~., data=lcdfTrn %>% select(-varsOmit), method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))

#Do we want to prune the tree -- check for performance with different cp levels
printcp(lcDT1)
lcDT1p<- prune.rpart(lcDT1, cp=0.0003)

#......

```


Performance evaluation
```{r}
#Evaluate performance
predTrn=predict(lcDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)
table(pred = predict(lcDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcDT1,lcdfTst, type='class') ==lcdfTst$loan_status)

#With a different classsification threshold
CTHRESH=0.3
predProbTrn=predict(lcDT1,lcdfTrn, type='prob')
predTrnCT = ifelse(predProbTrn[, 'Charged Off'] > CTHRESH, 'Charged Off', 'Fully Paid')
table(predTrnCT , true=lcdfTrn$loan_status)
# Or, to set the predTrnCT values as factors, and then get the confusion matrix
table(predictions=factor(predTrnCT, levels=c("Fully Paid", "Charged Off")), actuals=lcdfTrn$loan_status)



#Or you can use the confusionMatrix fuction from the caret package
library(caret)
confusionMatrix(predTrn, lcdfTrn$loan_status)
    #if you get an error saying that the 'e1071' package is required, 
    # you should install and load that too
#Notice that the output says 
#   'Positive' class: Fully Paid
#So,the confusionMatrix based performance measures are based 
#  on the "Fully Paid" class as the class of interest.
# If you want to get performance measure for "Charged Off", use 
#    the positive- paremeter
confusionMatrix(predTrn, lcdfTrn$loan_status, positive="Charged Off")


#ROC plot
library(ROCR)

score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
    #label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values


#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)


```




Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
